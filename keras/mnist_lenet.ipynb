{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN example with Keras\n",
    "\n",
    "In this example, we classify hand-written digits of the MNIST dataset with LeNet5. Please read CNN example with Chainer for the detail of the procedure, the dataset, and the architecture. This example is based on the official example in Keras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basics of Keras\n",
    "\n",
    "### Model\n",
    "\n",
    "**keras.engine.Layer**\n",
    "\n",
    "* Building block of models.\n",
    "* Parameterized functions (e.g. ``Dense``, ``Convolution2D``), activation functions (instances of ``Activation`` class) or shape transformations (e.g. ``Flatten``) are the examples of ``Layer`` class.\n",
    "\n",
    "**keras.model.Sequential**\n",
    "\n",
    "* Container of layers.\n",
    "* Users sequentially add layers with ``Sequential.add()`` method.\n",
    "\n",
    "\n",
    "### Backend\n",
    "\n",
    "Keras relies on third-party libraries for low-level operations on tensors. Currently, Theano and TensorFlow are available as backends. Users can switch the backend by several ways (see [the official instruction](http://keras.io/backend/) for details.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Codes\n",
    "\n",
    "### 1. Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"dim_ordering\" determine how an image is represented as an 4-dimensional array.\n",
    "\n",
    "* dim_ordering = 'th' (THeano)    : (batchsize, channels, rows, columns)\n",
    "* dim_ordering = 'tf' (TensorFlow): (batchsize, rows, columns, channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "theano\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "print(K._BACKEND)\n",
    "if K.image_dim_ordering() == 'tf':\n",
    "    K.set_image_dim_ordering('th')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Prepare dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], 1, 28, 28).astype('float32')\n",
    "X_test = X_test.reshape(X_test.shape[0], 1, 28, 28).astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "Y_train = np_utils.to_categorical(y_train, 10)\n",
    "Y_test = np_utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GeForce GTX 1080 (CNMeM is disabled, cuDNN 5110)\n",
      "/home/delta/.pyenv/versions/anaconda3-2.5.0/lib/python3.5/site-packages/theano/sandbox/cuda/__init__.py:600: UserWarning: Your cuDNN version is more recent than the one Theano officially supports. If you see any problems, try updating Theano or downgrading cuDNN to version 5.\n",
      "  warnings.warn(warn)\n"
     ]
    }
   ],
   "source": [
    "# Set GPU mode\n",
    "gpu = 0\n",
    "if gpu >= 0:\n",
    "    from theano.sandbox import cuda\n",
    "    cuda.use(\"gpu{}\".format(gpu))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Prepare model and 4. Setup optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# The size of each image of MNIST is 28 x 28,\n",
    "# but LeNet5 is designed so that its input is 32 x 32.\n",
    "# So we add the padding of size (32 - 28) / 2 = 2.\n",
    "model.add(ZeroPadding2D(padding=(2, 2), input_shape=(1, 28, 28)))\n",
    "model.add(Convolution2D(6, 5, 5, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Convolution2D(16, 5, 5, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(120))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(84))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adadelta',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 2s - loss: 0.3651 - acc: 0.8881 - val_loss: 0.0858 - val_acc: 0.9731\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 2s - loss: 0.0839 - acc: 0.9744 - val_loss: 0.0608 - val_acc: 0.9809\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 2s - loss: 0.0623 - acc: 0.9814 - val_loss: 0.0472 - val_acc: 0.9846\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 2s - loss: 0.0513 - acc: 0.9843 - val_loss: 0.0421 - val_acc: 0.9859\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 2s - loss: 0.0442 - acc: 0.9867 - val_loss: 0.0412 - val_acc: 0.9861\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 2s - loss: 0.0390 - acc: 0.9881 - val_loss: 0.0338 - val_acc: 0.9892\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 2s - loss: 0.0348 - acc: 0.9893 - val_loss: 0.0350 - val_acc: 0.9878\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 2s - loss: 0.0313 - acc: 0.9905 - val_loss: 0.0340 - val_acc: 0.9890\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 2s - loss: 0.0280 - acc: 0.9915 - val_loss: 0.0388 - val_acc: 0.9870\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 2s - loss: 0.0255 - acc: 0.9924 - val_loss: 0.0303 - val_acc: 0.9902\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 2s - loss: 0.0231 - acc: 0.9932 - val_loss: 0.0276 - val_acc: 0.9916\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 2s - loss: 0.0216 - acc: 0.9933 - val_loss: 0.0291 - val_acc: 0.9904\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f96a6b6fc18>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, batch_size=128, nb_epoch=12,\n",
    "          verbose=1, validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.0291142435878\n",
      "Test accuracy: 0.9904\n"
     ]
    }
   ],
   "source": [
    "# Evaluation (optional)\n",
    "score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Save models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('lenet5.json', 'w') as o:\n",
    "    o.write(model.to_json())\n",
    "model.save_weights('lenet5.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
